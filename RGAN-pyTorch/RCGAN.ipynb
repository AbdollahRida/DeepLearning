{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "#from skimage.io import imsave\n",
    "import os\n",
    "#from tensorboardX import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "def gpu(tensor, gpu=use_gpu):\n",
    "    if gpu:\n",
    "        return tensor.cuda()\n",
    "    else:\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 28\n",
    "img_width = 28\n",
    "img_size = img_height * img_width\n",
    "\n",
    "to_train = True\n",
    "to_restore = False\n",
    "output_path = \"output\"\n",
    "\n",
    "max_epoch = 1000\n",
    "\n",
    "hg_size = 150\n",
    "hd_size = 300\n",
    "z_size = 100\n",
    "batch_size = 256\n",
    "seq_size=4\n",
    "n_hidden=300\n",
    "tr_data_num=60000;\n",
    "g_num_layers=2;\n",
    "d_num_layers=2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/majrda/Scripts/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, stddev = 0.1):\n",
    "        super().__init__()\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def forward(self, din):\n",
    "        if self.training:\n",
    "            return din + torch.autograd.Variable(torch.randn(din.size()).cuda() * self.stddev)\n",
    "        return din"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelG(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        super(ModelG, self).__init__()\n",
    "\n",
    "        self.lstm_G = nn.LSTM(input_size = z_dim + 10, \n",
    "                   hidden_size = n_hidden,\n",
    "                   num_layers = g_num_layers,\n",
    "                   bias = False,\n",
    "                   dropout = .5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc_G = nn.Linear(n_hidden, img_size)\n",
    "\n",
    "    def forward(self, x, label_onehot):\n",
    "        x = torch.cat([x, label_onehot], 1)\n",
    "        x = x.unsqueeze(1)\n",
    "        #print(x.size())\n",
    "        output, _ = self.lstm_G(x)\n",
    "        output = torch.tanh(self.fc_G(self.relu(output)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelD, self).__init__()\n",
    "        self.lstm_D = nn.LSTM(input_size = img_size + 10, \n",
    "                               hidden_size = n_hidden,\n",
    "                               num_layers = d_num_layers)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.MLP = nn.Linear(n_hidden, 1)\n",
    "        \n",
    "        self.noise = GaussianNoise(.3)\n",
    "\n",
    "    def forward(self, x, label_onehot):\n",
    "        #print(x.size())\n",
    "        x = torch.cat([x, label_onehot], 2)\n",
    "        #print(x.size())\n",
    "        x = self.noise(x)\n",
    "        outputs, _ = self.lstm_D(x)\n",
    "        #print(outputs.size())\n",
    "        res = self.MLP(self.relu(outputs[:, -1, :]))\n",
    "        #print(res)\n",
    "        y_data = torch.sigmoid(res.narrow(0, 0, x[0].shape[0]))\n",
    "        return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root=root_dir, train=True, download=False, transform=transforms.ToTensor())\n",
    "mnist_testset = datasets.MNIST(root=root_dir, train=False, download=False, transform=transforms.ToTensor())\n",
    "\n",
    "X_train = mnist_trainset.train_data.numpy()\n",
    "Y_train = mnist_trainset.train_labels.numpy()\n",
    "\n",
    "X_test = mnist_testset.test_data.numpy()\n",
    "Y_test = mnist_testset.test_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "nb_epochs = 100\n",
    "\n",
    "loss_D_epoch = []\n",
    "loss_G_epoch = []\n",
    "\n",
    "z_dim = z_size\n",
    "label_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [00:32,  3.55it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7f2dc1a4e034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mlabel_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mD_scores_on_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_CD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_scores_on_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-97c7521fc7a8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, label_onehot)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_onehot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(x.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(outputs.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7a6a71d8da7e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, din)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net_CG = gpu(ModelG(z_size))\n",
    "net_CD = gpu(ModelD())\n",
    "\n",
    "optimizer_CG = torch.optim.Adam(net_CG.parameters(),lr=lr)\n",
    "optimizer_CD = torch.optim.Adam(net_CD.parameters(),lr=lr)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    print(\"Epoch: \", e)\n",
    "    rperm = np.random.permutation(X_train.shape[0]);\n",
    "    np.take(X_train,rperm,axis=0,out=X_train);\n",
    "    np.take(Y_train,rperm,axis=0,out=Y_train);\n",
    "    real_samples = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "    real_labels = torch.from_numpy(Y_train).type(torch.LongTensor)\n",
    "    loss_G = 0\n",
    "    loss_D = 0\n",
    "    for real_batch, real_batch_label in tqdm(zip(real_samples.split(batch_size),real_labels.split(batch_size))):\n",
    "        \n",
    "        #print(real_batch.size())\n",
    "        #print(real_batch.shape[0])\n",
    "        real_batch = real_batch.view(real_batch.shape[0], 1, img_size).cuda()\n",
    "        #print(real_batch.size())\n",
    "            \n",
    "        #improving D\n",
    "        z = gpu(torch.empty(real_batch.shape[0],z_dim).normal_())\n",
    "        #print(real_batch_label)\n",
    "        real_batch_label_ = torch.unsqueeze(real_batch_label, 1)\n",
    "        #print(real_batch_label_.size())\n",
    "        label_onehot = torch.FloatTensor(real_batch.shape[0], label_dim).zero_()\n",
    "        #print(label_onehot.size())\n",
    "        label_onehot = gpu(label_onehot.scatter(1, real_batch_label_, 1).type(torch.FloatTensor))\n",
    "        #print(label_onehot.size())\n",
    "        \n",
    "        fake_batch = net_CG(z, label_onehot)\n",
    "        #print(\"FB size: \", fake_batch.size())\n",
    "        label_onehot = label_onehot.unsqueeze(1)\n",
    "        #print(label_onehot.size())\n",
    "        D_scores_on_real = net_CD(gpu(real_batch), label_onehot)\n",
    "        D_scores_on_fake = net_CD(fake_batch, label_onehot)\n",
    "        \n",
    "        loss = -torch.mean(torch.log(1-D_scores_on_fake) + torch.log(D_scores_on_real))\n",
    "        optimizer_CD.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_CD.step()\n",
    "        loss_D += loss\n",
    "            \n",
    "            # improving G\n",
    "        z = gpu(torch.empty(real_batch.shape[0],z_dim).normal_())\n",
    "        real_batch_label_ = torch.unsqueeze(real_batch_label, 1)\n",
    "        #print(real_batch_label_.size())\n",
    "        label_onehot = torch.FloatTensor(real_batch.shape[0], label_dim).zero_()\n",
    "        #print(label_onehot.size())\n",
    "        label_onehot = gpu(label_onehot.scatter(1, real_batch_label_, 1).type(torch.FloatTensor))\n",
    "        #print(label_onehot)\n",
    "        fake_batch = net_CG(z, label_onehot)\n",
    "        \n",
    "        label_onehot = label_onehot.unsqueeze(1)\n",
    "        D_scores_on_fake = net_CD(fake_batch, label_onehot)\n",
    "            \n",
    "        loss = -torch.mean(torch.log(D_scores_on_fake))\n",
    "        optimizer_CG.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_CG.step()\n",
    "        loss_G += loss\n",
    "                    \n",
    "    loss_D_epoch.append(loss_D)\n",
    "    loss_G_epoch.append(loss_G)\n",
    "    print(\"Loss on Generator this epoch: {}\\nLoss on Discriminator this epoch: {}\".format(loss_G, loss_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_D_epoch, color ='b')\n",
    "plt.plot(loss_G_epoch, color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = gpu(torch.empty(Y_test.size,z_size).normal_())\n",
    "real_batch_label = torch.from_numpy(Y_test).type(torch.LongTensor)\n",
    "real_batch_label_ = torch.unsqueeze(real_batch_label, 1)\n",
    "#print(real_batch_label_.size())\n",
    "label_onehot = torch.FloatTensor(Y_test.size, label_dim).zero_()\n",
    "#print(label_onehot.size())\n",
    "label_onehot = gpu(label_onehot.scatter(1, real_batch_label_, 1).type(torch.FloatTensor))\n",
    "#print(label_onehot.size())\n",
    "\n",
    "fake_samples = net_CG(z, label_onehot)\n",
    "fake_data = fake_samples.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fake_data[0, 0]\n",
    "\n",
    "x = x.reshape(28, 28)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(x, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
